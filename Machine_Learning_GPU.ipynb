{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c7ca7d",
   "metadata": {},
   "source": [
    "### > Criando dados artificiais para teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43bb5002-7c47-42f3-b01f-808848306f03",
   "metadata": {
    "id": "43bb5002-7c47-42f3-b01f-808848306f03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.381891</td>\n",
       "      <td>-2.298180</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.428387</td>\n",
       "      <td>-3.233190</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.668118</td>\n",
       "      <td>-7.568221</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.194736</td>\n",
       "      <td>4.380275</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.432270</td>\n",
       "      <td>-7.989467</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>4.920474</td>\n",
       "      <td>-9.510699</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>1.336689</td>\n",
       "      <td>5.658974</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>2.522857</td>\n",
       "      <td>4.292397</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>3.988511</td>\n",
       "      <td>6.646187</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>2.861511</td>\n",
       "      <td>2.548996</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x         y  label\n",
       "0      1.381891 -2.298180    2.0\n",
       "1      1.428387 -3.233190    2.0\n",
       "2      3.668118 -7.568221    1.0\n",
       "3      5.194736  4.380275    0.0\n",
       "4      4.432270 -7.989467    1.0\n",
       "...         ...       ...    ...\n",
       "14995  4.920474 -9.510699    1.0\n",
       "14996  1.336689  5.658974    0.0\n",
       "14997  2.522857  4.292397    0.0\n",
       "14998  3.988511  6.646187    0.0\n",
       "14999  2.861511  2.548996    0.0\n",
       "\n",
       "[15000 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dask_cudf #dask permite excução em multiplas gpu\n",
    "#gdf = dask_cudf.read_csv(\"/path/to/my/data-*.csv\")  # Your CSV files can be larger than GPU memory\n",
    "#and you can use multiple GPUs to process this data\n",
    "\n",
    "import cudf #cria o dataframe na gpu\n",
    "from cuml.datasets import make_blobs\n",
    "import time\n",
    "\n",
    "X, y = make_blobs(n_samples=15000, centers=3, n_features=5)\n",
    "\n",
    "\n",
    "tabela_artificial_cudf = cudf.DataFrame(dict(x=X[:,0], y=X[:,1],label=y))\n",
    "coluna_resposta_cudf = tabela_artificial_cudf['label']\n",
    "\n",
    "tabela_artificial_cudf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a662e74d",
   "metadata": {},
   "source": [
    "### > Implementando o algoritmo KMeans na GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a02d94d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de execução:  3.7299327850341797\n",
      "Resultado: 4928 de 15000 amostras foram corretamente preditas.\n",
      "Acurácia: 0.33\n"
     ]
    }
   ],
   "source": [
    "from cuml.cluster import KMeans\n",
    "\n",
    "#inicializando as variáveis\n",
    "inicio = time.time()\n",
    "tabela_artificial_cudf = cudf.DataFrame(dict(x=X[:,0], y=X[:,1]))\n",
    "coluna_resposta_cudf = y\n",
    "\n",
    "#Treinando o modelo pelo algoritmo KMeans\n",
    "kmeans_cuml = KMeans(n_clusters = 3, random_state = 0)\n",
    "kmeans_cuml.fit(tabela_artificial_cudf)\n",
    "\n",
    "#capturando as amostras preditas\n",
    "labels = kmeans_cuml.labels_\n",
    "#confrontando com os valores reais\n",
    "acertos = sum(coluna_resposta_cudf == labels)\n",
    "\n",
    "#imprimindo o tempo de execução\n",
    "print(\"Tempo de execução: \" ,time.time() - inicio) \n",
    "#imprimindo a acurácia do modelo\n",
    "print(\"Resultado: %d de %d amostras foram corretamente preditas.\" % (acertos, coluna_resposta_cudf.size))\n",
    "print('Acurácia: {0:0.2f}'. format(acertos/float(coluna_resposta_cudf.size)))\n",
    "\n",
    "del coluna_resposta_cudf #destroi objeto liberando memoria da gpu\n",
    "del tabela_artificial_cudf \n",
    "del labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1212200b",
   "metadata": {},
   "source": [
    "### > Buscando informações da GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4244e965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 10 18:59:01 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.76.02    Driver Version: 517.48       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:03:00.0  On |                  N/A |\n",
      "| 30%   45C    P8    18W / 270W |   3550MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       190      C   /python3.9                      N/A      |\n",
      "|    0   N/A  N/A       206      C   /python3.9                      N/A      |\n",
      "|    0   N/A  N/A       373      C   /python3.9                      N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# traz informaçõs da gpu\n",
    "!nvidia-smi\n",
    "# comando para finalizar o processo na gpu pelo pid\n",
    "#nvidia-smi | grep 'python' | awk '{ print $3 }' | xargs -n1 kill -9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b1363",
   "metadata": {},
   "source": [
    "### Implementando a biblioteca CUDA do compilador NUMBA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69f8deec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "17\n",
      "4\n",
      "5\n",
      "18\n",
      "19\n",
      "6\n",
      "7\n",
      "14\n",
      "15\n",
      "2\n",
      "3\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "0\n",
      "1\n",
      "8\n",
      "9\n",
      "<CUDA device 0 'b'NVIDIA GeForce RTX 3070''>\n",
      "GPU compute capability:  (8, 6)\n",
      "GPU total number of SMs:  46\n"
     ]
    }
   ],
   "source": [
    "# NUMBA é um compilador python de alta performance para funções matemáticas e array baseada em decorators(@xxx).\n",
    "# CUDA é uma biblioteca do NUMBA para execução em GPU(Placa de vídeo) \n",
    "from numba import cuda #numba aceita apenas alguns tipos de variaveis como float e integer\n",
    "\n",
    "@cuda.jit(device=True) #funcao executada na gpu e só pode ser chamada de dentro da gpu por uma kernel ou outra device function, possui retorno\n",
    "def a_device_function(a, b):\n",
    "    return a + b\n",
    "\n",
    "@cuda.jit #função kernel é chamada pela cpu e executada na gpu. jit: compilado em tempo de execução\n",
    "def increment_by_one(algum_array):\n",
    "    a_device_function(a,b)\n",
    "    pos = cuda.grid(1) #grid1 é o array unidimensional que contémos id das threads que são executadas simutanemanete\n",
    "    if pos < algum_array.size: # garante que o index estara no range do array passado como argumento\n",
    "        algum_array[pos] += 1\n",
    "        \n",
    "@cuda.jit #função kernel é chamada pela cpu e executada na gpu. jit: compilado em tempo de execução\n",
    "def teste_imprime_pos():\n",
    "    pos = cuda.grid(1) #grid1 é o array unidimensional de threads que são executadas simutanemanete\n",
    "    print(pos)\n",
    "\n",
    "\n",
    "\n",
    "#128 é o número de blocos por grid e 1024 o número de threads por bloco,\n",
    "#multiplica-se os dois para obter o número total de treahds\n",
    "#o limite desses números variam de acordo com a qualidade da GPU\n",
    "\n",
    "#teste_imprime_pos[128,1024]() #ira executar 128*1024= 131.072 threads simultaneamente imprimindo o id da thread(pos)\n",
    "teste_imprime_pos[10,2]() #ira executar 10*2= 20 threads simultaneamente imprimindo o id da thread(pos)\n",
    "#perceba que os id´s não são impressos em ordem pois são executados simultâneamente.\n",
    "\n",
    "device = cuda.get_current_device()\n",
    "my_sms = getattr(device, 'MULTIPROCESSOR_COUNT')\n",
    "my_cc = device.compute_capability\n",
    "\n",
    "print(device)\n",
    "print(\"GPU compute capability: \" , my_cc)\n",
    "print(\"GPU total number of SMs: \" , my_sms)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9 (rapids-22.08)",
   "language": "python",
   "name": "rapids-22.08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
